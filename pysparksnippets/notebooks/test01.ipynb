{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# fundamentals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'SparkContext' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-b23d28e02927>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mspark\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSparkSession\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuilder\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetOrCreate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m \u001B[0mdbutils\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdbu\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDBUtils\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mspark\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msparkContext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[0mdata_url\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'https://github.com/jtviegas/datasets/raw/main/fundamentals.zip'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'SparkContext' object is not callable"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "fundamentals exercise\n",
    "\"\"\"\n",
    "from IPython.core.display import display\n",
    "from pyspark import dbutils as dbu\n",
    "from requests import get\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "dbutils = dbu.DBUtils(spark.sparkContext())\n",
    "\n",
    "data_url = 'https://github.com/jtviegas/datasets/raw/main/fundamentals.zip'\n",
    "zip_file_path = '/tmp/fundamentals.zip'\n",
    "local_folder = '/tmp'\n",
    "companies_file = 'companies_subset.csv'\n",
    "indicators_file = 'indicators_subset.csv'\n",
    "parquet_file = '/tmp/fundamentals/parquet'\n",
    "\n",
    "local_companies = 'file:{}/{}'.format(local_folder,companies_file)\n",
    "local_indicators = 'file:{}/{}'.format(local_folder,indicators_file)\n",
    "dbfs_companies = 'dbfs:{}/{}'.format(local_folder,companies_file)\n",
    "dbfs_indicators = 'dbfs:{}/{}'.format(local_folder,indicators_file)\n",
    "\n",
    "with open(zip_file_path, \"wb\") as file:\n",
    "  res = get(data_url)\n",
    "\n",
    "  file.write(res.content)\n",
    "\n",
    "with ZipFile(zip_file_path, 'r') as zipfile:\n",
    "  files = zipfile.namelist()\n",
    "  for file in files:\n",
    "    zipfile.extract(file, local_folder)\n",
    "\n",
    "os.listdir(local_folder)\n",
    "dbutils.fs.mv(local_companies, dbfs_companies)\n",
    "dbutils.fs.mv(local_indicators, dbfs_indicators)\n",
    "\n",
    "\n",
    "dfc = spark.read.format('csv').option('inferSchema', 'true').option('header','true').load(dbfs_companies)\n",
    "dfi = spark.read.format('csv').option('inferSchema', 'true').option('header','true').load(dbfs_indicators)\n",
    "dbutils.fs.rm(parquet_file, recurse=True)\n",
    "dfc.join(dfi, ['company_id'], 'left').write.parquet(parquet_file)\n",
    "\n",
    "df = spark.read.parquet(parquet_file)\n",
    "dbutils.fs.rm(dbfs_companies)\n",
    "dbutils.fs.rm(dbfs_indicators)\n",
    "dbutils.fs.rm(local_companies)\n",
    "dbutils.fs.rm(local_indicators)\n",
    "dbutils.fs.rm(zip_file_path)\n",
    "\n",
    "print(spark.conf.get(\"spark.databricks.io.cache.enabled\"))\n",
    "display(df)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}